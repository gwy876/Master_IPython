{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-Multiclass with NSL-KDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, I am using the same inputs as the compared SDN-DNN solution to enable qualitative comparsion amongst the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "header_col = pd.read_csv(os.path.join('NSL_KDD', 'Field Names.csv'), header=None)\n",
    "header_col = header_col.append(pd.DataFrame([['label','symbolic'],['unknown','continuous']]))\n",
    "\n",
    "header_names = header_col[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type  src_bytes  dst_bytes  count  srv_count\n",
       "0         0           tcp        491          0      2          2\n",
       "1         0           udp        146          0     13          1\n",
       "2         0           tcp          0          0    123          6\n",
       "3         0           tcp        232       8153      5          5\n",
       "4         0           tcp        199        420     30         32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftrain = os.path.join('NSL_KDD','KDDTrain+.csv')\n",
    "kdd_train = pd.read_csv(ftrain, header=None, names=header_names)\n",
    "\n",
    "# split off labels\n",
    "kdd_train_labels = kdd_train['label']\n",
    "\n",
    "# only keep columns that are actually used\n",
    "used_fields = ['duration', 'protocol_type', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "kdd_train = kdd_train.filter(used_fields)\n",
    "kdd_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22538</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>794</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>317</td>\n",
       "      <td>938</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22540</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>54540</td>\n",
       "      <td>8314</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22541</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22542</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration protocol_type  src_bytes  dst_bytes  count  srv_count\n",
       "22538         0           tcp        794        333      1          1\n",
       "22539         0           tcp        317        938      2         11\n",
       "22540         0           tcp      54540       8314      5         10\n",
       "22541         0           udp         42         42      4          6\n",
       "22542         0           tcp          0          0      4         10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftest = os.path.join('NSL_KDD','KDDTest+.csv')\n",
    "kdd_test = pd.read_csv(ftest, header=None, names=header_names)\n",
    "\n",
    "# split off labels\n",
    "kdd_test_labels = kdd_test['label']\n",
    "\n",
    "# only keep columns that are actually used\n",
    "kdd_test = kdd_test.filter(used_fields)\n",
    "\n",
    "kdd_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# tokenize the LABELS\n",
    "label_tokenizer = Tokenizer(num_words=50, filters='')\n",
    "label_tokenizer.fit_on_texts((kdd_train_labels.append(kdd_test_labels)).values)\n",
    "\n",
    "# Run the fitted tokenizer on the label column and save the encoded data as dataframe\n",
    "kdd_train_labels = label_tokenizer.texts_to_sequences(kdd_train_labels)\n",
    "kdd_train_labels = np.concatenate(kdd_train_labels).ravel()\n",
    "\n",
    "# as the Encoder documentation states, 0 will never assigned to a label.\n",
    "# I, on the other hand, need an index starting with 0. So we substract 1 of all classes.\n",
    "kdd_train_labels = kdd_train_labels -1\n",
    "\n",
    "# Do the same for the test labels\n",
    "kdd_test_labels = label_tokenizer.texts_to_sequences(kdd_test_labels)\n",
    "kdd_test_labels = np.concatenate(kdd_test_labels).ravel()\n",
    "kdd_test_labels = kdd_test_labels -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a big dataframe out of both sets to train the tokenizer\n",
    "full = pd.concat([kdd_train, kdd_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the protocol_type column\n",
    "protocol_tokenizer = Tokenizer(num_words=50, filters='')\n",
    "protocol_tokenizer.fit_on_texts(full['protocol_type'])\n",
    "\n",
    "train_enc = protocol_tokenizer.texts_to_sequences(kdd_train['protocol_type'])\n",
    "test_enc = protocol_tokenizer.texts_to_sequences(kdd_test['protocol_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>protocol_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>0</td>\n",
       "      <td>2231</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  count  srv_count  protocol_type\n",
       "125968         0          0          0    184         25              1\n",
       "125969         8        105        145      2          2              2\n",
       "125970         0       2231        384      1          1              1\n",
       "125971         0          0          0    144          8              1\n",
       "125972         0        151          0      1          1              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the column containing strings\n",
    "kdd_train.drop('protocol_type', axis=1, inplace=True)\n",
    "# ... and add the encoded column instead\n",
    "kdd_train = pd.concat([kdd_train, pd.DataFrame(train_enc,columns=['protocol_type'])], axis=1, sort=False)\n",
    "kdd_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>protocol_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22538</th>\n",
       "      <td>0</td>\n",
       "      <td>794</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22539</th>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>938</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22540</th>\n",
       "      <td>0</td>\n",
       "      <td>54540</td>\n",
       "      <td>8314</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22541</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22542</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  src_bytes  dst_bytes  count  srv_count  protocol_type\n",
       "22538         0        794        333      1          1              1\n",
       "22539         0        317        938      2         11              1\n",
       "22540         0      54540       8314      5         10              1\n",
       "22541         0         42         42      4          6              2\n",
       "22542         0          0          0      4         10              1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd_test.drop('protocol_type', axis=1, inplace=True)\n",
    "kdd_test = pd.concat([kdd_test, pd.DataFrame(test_enc,columns=['protocol_type'])], axis=1, sort=False)\n",
    "kdd_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "Shape of the final training dataset: (125973, 6)\n",
      "Outer type: <class 'numpy.ndarray'>\n",
      "Single entry type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "kdd_train = min_max_scaler.fit_transform(kdd_train)\n",
    "\n",
    "print(\"Training Dataset:\")\n",
    "print(\"Shape of the final training dataset:\", kdd_train.shape)\n",
    "print(\"Outer type:\", type(kdd_train))\n",
    "print(\"Single entry type:\", type(kdd_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset:\n",
      "Shape of the final test dataset: (22543, 6)\n",
      "Outer type: <class 'numpy.ndarray'>\n",
      "Single entry type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "kdd_test = min_max_scaler.fit_transform(kdd_test)\n",
    "\n",
    "print(\"Test Dataset:\")\n",
    "print(\"Shape of the final test dataset:\", kdd_test.shape)\n",
    "print(\"Outer type:\", type(kdd_test))\n",
    "print(\"Single entry type:\", type(kdd_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Preqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os.path import exists, join\n",
    "\n",
    "# Define some semi-global stuff\n",
    "\n",
    "# test_size = 0.3 # There's a separate test set!\n",
    "batch_size = 10\n",
    "no_of_classes = len(np.unique(np.concatenate((kdd_train_labels, kdd_test_labels))))\n",
    "\n",
    "run_date = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "runtype_name = 'nsl-kdd-lstm-multiclass'\n",
    "log_folder_path = os.path.join('logs',runtype_name + '-{}'.format(run_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of scaled train entries:\t 125973\n",
      "No of train labels:\t\t 125973\n",
      "-----------\n",
      "No of test entries:\t\t 22543\n",
      "No of test labels:\t\t 22543\n"
     ]
    }
   ],
   "source": [
    "print(\"No of scaled train entries:\\t\", len(kdd_train))\n",
    "print(\"No of train labels:\\t\\t\", len(kdd_train_labels))\n",
    "print(\"-----------\")\n",
    "print(\"No of test entries:\\t\\t\", len(kdd_test))\n",
    "print(\"No of test labels:\\t\\t\", len(kdd_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras Embedding Layer expects a maximum vocabulary size, which we can simply calculate by finding max() of the encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum vocabulary size: 2\n"
     ]
    }
   ],
   "source": [
    "voc_size = (kdd_train.max()+1).astype('int64')\n",
    "print(\"Maximum vocabulary size:\", voc_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='acc', # Which metric to monitor\n",
    "        patience=3     # Interrupt training after acc has stopped improving for more than 1 epoch\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/'+runtype_name+'-{}.h5'.format(run_date),\n",
    "        monitor='val_loss',   \n",
    "        save_best_only=True    # Only save one. Only overwrite this one if val_loss has improved\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=log_folder_path\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          64        \n",
      "_________________________________________________________________\n",
      "LSTMnet (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                1320      \n",
      "=================================================================\n",
      "Total params: 9,704\n",
      "Trainable params: 9,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 125973 samples, validate on 22543 samples\n",
      "Epoch 1/10\n",
      "125973/125973 [==============================] - 56s 443us/step - loss: 1.0882 - acc: 0.5584 - val_loss: 4.8391 - val_acc: 0.4313\n",
      "Epoch 2/10\n",
      "125973/125973 [==============================] - 53s 419us/step - loss: 1.0768 - acc: 0.5598 - val_loss: 4.9779 - val_acc: 0.4313\n",
      "Epoch 3/10\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 1.0784 - acc: 0.5595 - val_loss: 5.0074 - val_acc: 0.4313\n",
      "Epoch 4/10\n",
      "125973/125973 [==============================] - 56s 443us/step - loss: 1.0811 - acc: 0.5594 - val_loss: 5.1048 - val_acc: 0.4313\n",
      "Epoch 5/10\n",
      "125973/125973 [==============================] - 56s 442us/step - loss: 1.0867 - acc: 0.5583 - val_loss: 5.0454 - val_acc: 0.4389\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# see https://stackoverflow.com/a/49436133/3864726\n",
    "# This is especially important in an environment like Jupyter, where the Kernel keeps on running\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, 32)) \n",
    "model.add(LSTM(32, name='LSTMnet'))\n",
    "model.add(Dense(no_of_classes, activation='softmax')) # Multiclass classification. For binary, one would use i.e. sigmoid\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy', # Multiclass classification! Binary would be binary_crossentropy\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, to_file='model-nsl-kdd-lstm-multiclass.png', show_layer_names=True, show_shapes=True)\n",
    "\n",
    "history = model.fit(kdd_train, kdd_train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1,\n",
    "                    validation_data=(kdd_test, kdd_test_labels),\n",
    "                    callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
